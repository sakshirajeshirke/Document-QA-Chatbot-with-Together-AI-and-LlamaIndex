# Document-QA-Chatbot-with-Together-AI-and-LlamaIndex
---

````markdown
# ğŸ¤– Document QA Chatbot with Together AI & LlamaIndex

A smart, multi-document Question Answering (QA) chatbot built with **Streamlit**, **Together AI**, and **LlamaIndex**. Upload your PDFs, DOCX, or TXT files and instantly ask questions in natural language. Ideal for insurance agents, legal professionals, students, and knowledge workers.

---

## ğŸš€ Features

âœ¨ Ask questions directly from uploaded documents  
ğŸ“š Supports multi-document queries  
ğŸ§  Uses Together AIâ€™s powerful LLMs & Embeddings  
âš™ï¸ LlamaIndex for flexible indexing (VectorStore, etc.)  
ğŸ“Š Langfuse integration for observability  
ğŸ¨ Clean, responsive Streamlit UI  

---

## ğŸ§  Powered By

| Component         | Technology Used                                  |
|------------------|---------------------------------------------------|
| **Frontend**      | `Streamlit`                                       |
| **LLM**           | `Together AI` (Mistral, LLaMA, Qwen, etc.)        |
| **Embeddings**    | `togethercomputer/m2-bert-80M-8k-retrieval`       |
| **Indexing**      | `LlamaIndex` with `VectorStoreIndex`             |
| **Tracing**       | `Langfuse` for monitoring and logging             |
| **Supported Files**| `.pdf`, `.docx`, `.txt`                          |

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/your-username/Document-QA-Chatbot-with-Together-AI-and-LlamaIndex.git
cd Document-QA-Chatbot-with-Together-AI-and-LlamaIndex

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install required packages
pip install -r requirements.txt
````

---

## ğŸ” Environment Setup

Create a `.env` file in the root directory and add the following:

```env
TOGETHER_API_KEY=your_together_api_key
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
LANGFUSE_SECRET_KEY=your_langfuse_secret_key
LANGFUSE_HOST=https://cloud.langfuse.com  # Optional
```

> âš ï¸ **Note:** Don't commit your `.env` file. Add it to `.gitignore`!

---

## â–¶ï¸ How to Run

```bash
streamlit run lang.py
```

Open in your browser at `http://localhost:8501`.

---

## ğŸ§ª Sample Use Cases

* ğŸ” Extract specific info from insurance claim documents
* ğŸ“‘ Compare multiple contracts or policies
* ğŸ“ Ask questions from research papers or study material
* ğŸ§¾ Search summaries in invoices and receipts

---

## ğŸ“¸ Screenshots

# Upload & Ask                                                         
| ![upload](![chat1](![chat1](https://github.com/user-attachments/assets/5bfd6076-ec90-4895-ba2c-3b9c99f671e7)))
# Chat Interface 
| ![chat](![chat2](https://github.com/user-attachments/assets/d6074b78-ea57-4982-a6e5-2c432919ba4f)) |
# langfuse 
| ![langfuse] (![chatbot2](![![chatbot2](https://github.com/user-attachments/assets/9d5dd5ff-8d16-4a22-9188-6098d795f8e2)
]())) |
---

## ğŸ“ Project Structure

```
â”œâ”€â”€ lang.py               # Main Streamlit app
â”œâ”€â”€ .env                 # API keys (excluded from repo)
â”œâ”€â”€ requirements.txt     # Required Python packages
â”œâ”€â”€ README.md            # Project info
```

---

## ğŸ“Š Langfuse Monitoring (Optional)

Track and trace your LLM responses using Langfuse.

* Get keys from [Langfuse Cloud](https://cloud.langfuse.com/)
* Easily trace LLM performance and prompt interactions

---

## ğŸ“Œ Roadmap

* âœ… Multi-document support
* âœ… Together AI + Langfuse integration
* â³ PDF summarization
* â³ Qdrant/Pinecone support for persistent storage
* â³ Batch preprocessing

---

## ğŸ›¡ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ™Œ Acknowledgements

* [Together AI](https://www.together.ai/)
* [LlamaIndex](https://www.llamaindex.ai/)
* [Langfuse](https://www.langfuse.com/)
* [Streamlit](https://streamlit.io/)

---

Made with â¤ï¸ for smart document understanding.

```
